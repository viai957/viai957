

<!--
**viai957/viai957** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

![](https://komarev.com/ghpvc/?username=viai957&color=red)
### 
<!-- LIST:START -->
---
Lately Iâ€™ve been working with LLMs for the past few months across every part of the technology stack: from low-level (pytorch and ggml) to abstraction and orchestration layers (LangChain, Llama Index); from OpenAI to Claude to Llama and back; from prompt engineering to agent planning; from development to deployment, and now Iâ€™m working on monitoring and evaluation, pretraining.

Iâ€™ve also been talking with leaders across every part of the ecosystem: from the 10BedICU, OpenAI core team to futuristic indie projects at the AGI House to old-school businesses like Pratham Books who donâ€™t even have a tech team that are desperate to use the technology.

One thing stands out across the landscape: LLMs are a new kind of product that have new kinds of user behavior, business expectations, and engineering requirements. I want to talk about a specific comment I hear a lot of people talk about, and how it creates a symphony of confusion and opportunity for designers, operators and engineers to build great products.
<!-- LIST:END -->
---
### ðŸ“• My Latest Projects:
<!-- LIST:START -->
- [LexiGenesis ]([LexiGenesis](https://github.com/viai957/LexiGenesis) ) An repo to explain and understand how the evolution of LLM goes from pretraining -> finetuning -> benchmarking -> deployment -> application development over it
<!-- LIST:END -->
---


